{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries with xarray\n",
    "\n",
    "* Modified by C. Gentemann for GHRSST Science Team Tutorial 2019, Rome, Italy\n",
    "* Modified by C. Gentemann for OceanHackWeek 2019, Seattle, WA\n",
    "* PODAACPY file search added by Lewis John McGibbney\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of this tutorial\n",
    "\n",
    "1. Searching for data at NASA's PODAAC\n",
    "1. Opening data\n",
    "1. Data plotting, exploration, subsetting\n",
    "1. Comparing two datasets\n",
    "1. Comparing timeseries of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Key features of `xarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "## Import python packages\n",
    "\n",
    "You are going to want numpy, pandas, matplotlib.pyplot, podaaacpy, and xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore') # filter some warning messages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "from lxml import objectify\n",
    "\n",
    "#for search capabilites import podaacpy\n",
    "import podaac.podaac as podaac\n",
    "from podaac import drive as podaacdrive\n",
    "import podaac.podaac_utils as putil\n",
    "\n",
    "# then create an instance of the Podaac class\n",
    "p = podaac.Podaac()\n",
    "\n",
    "with open('./podaac.ini', 'r') as f:\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read_file(f)\n",
    "    d = podaacdrive.Drive(None, \n",
    "                          config['drive']['urs_username'], \n",
    "                          config['drive']['urs_password'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of winds and SSTs during Hurricane Irene\n",
    "\n",
    "Irene was a massive storm, with tropical storm force winds extending outward 300 miles (485 km). The storm was also slow moving as it traversed the Mid-Atlantic. Irene claimed at least 48 lives and caused over 7 billion U.S. dollars in damages in the U.S. and 3.1 billion U.S. dollars of damage in the Caribbean. (source: https://www.ncdc.noaa.gov/sotc/tropical-cyclones/201113).\n",
    "\n",
    "For this tutorial we will use the podaacpy to search for SST and winds during Hurricane Irene and look at the change in upper ocean heat content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2011-08-24T00:00:00Z'\n",
    "end_time = '2011-09-15T23:59:59Z'\n",
    "\n",
    "dataset_id = 'PODAAC-GHGMR-4FJ04'  #MUR SST looked up on podaac website\n",
    "#dataset_id = 'PODAAC-GHCMC-4FM03'  #CMC SST looked up on podaac website\n",
    "\n",
    "gresult = p.granule_search(dataset_id=dataset_id,\n",
    "                           start_time=start_time,\n",
    "                           end_time=end_time,\n",
    "                           items_per_page='100')\n",
    "\n",
    "urls = putil.PodaacUtils.mine_opendap_urls_from_granule_search(gresult)\n",
    "\n",
    "urls_sst = [w[:-5] for w in urls]  #remove html from urlsurls_sst = [w.replace('-tools.jpl.nasa.gov/drive/files/', '-opendap.jpl.nasa.gov/opendap/') for w in urls_sst]\n",
    "\n",
    "print('num files:',len(urls_sst))\n",
    "print(urls_sst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the MUR SST dataset. Other tutorial examples [here](https://github.com/pydata/xarray/tree/master/examples).\n",
    "\n",
    "## 2. Examining your data\n",
    "\n",
    "* With well designed mdatasets that follow Climate Forecast (CF) conventions, you will usually get coordinates of lat,lon,time which makes it easy to select data and visualize it in different ways.  \n",
    "\n",
    "* Notice that the time is automatically converted into a np.datetime64 format which can be queried for month, day, etc.  All the variables that are CF compliant are automatically converted (if needed) and read in so that you can immediately start working with the data.  \n",
    "\n",
    "* Above, you can see that the dimensions are lat, lon, and time\n",
    "\n",
    "* The coordinates of the datasets are also lat,lon, and time\n",
    "\n",
    "\n",
    "use [xr.open_dataset](http://xarray.pydata.org/en/stable/generated/xarray.open_dataset.html) to open the provided url and print the dataset\n",
    "\n",
    "* url is a text string to an online dataset.  When you open a file, you can just use the file name and path or you can just use the url for files that are available online.  If you are running this on the cloud you could even call cloud located data\n",
    "\n",
    "* Here, we are reading in a global SST dataset called CMC from NASA's PO.DAAC\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a SST dataset using the filename retrieved by podaacpy\n",
    "Below, let's open MUR SSTs using xarray and a PODAAC OpenDAP URL.\n",
    "To open a file use [xr.open_dataset](http://xarray.pydata.org/en/stable/generated/xarray.open_dataset.html)\n",
    "\n",
    "The url filename we want to use is already included for you.  You can give a local filename or an opendap URL.\n",
    "\n",
    "Then just print out the file details by just typing the dataset name, ds_sst_mur\n",
    "\n",
    "## Metadata --- Examining your data\n",
    "\n",
    "\n",
    "* The data variable (analysed_sst) has the labeled dimensions and metadata attached.  You can see additional metadata (if it exists) by looking at the data variable of interest.  \n",
    "\n",
    "* Below, type \n",
    "```ds_sst_mur.ana``` then hit tab to autocomplete.  \n",
    "* Then run the cell by holding shift and pressing enter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open & Subset the data using .sel to the North Atlantic region using slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sst = xr.open_dataset(urls_sst[0])\n",
    "subset_sst = ds_sst.sel(lat=slice(15,45),lon=slice(-100,-40))\n",
    "print('opening:', urls_sst[0],subset_sst)\n",
    "subset_sst.analysed_sst.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the SST.  \n",
    "### Notice xarray adds labels and title to the plot and colorbar.  \n",
    "\n",
    "Sometimes the metadata is great and you get exactly the label you need, but sometimes you want to change the label.  Xarray plotting [help](http://xarray.pydata.org/en/stable/plotting.html). A really nice feature of xarray is that it uses the metadata to label the axis.  Let's change the colorbar label by changing the `long_name` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the attributes for `analysed_sst`\n",
    "print(subset_sst.analysed_sst.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the attributes for `analysed_sst`\n",
    "subset_sst.analysed_sst.attrs['units']='K'\n",
    "subset_sst.analysed_sst.attrs['long_name']='SST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2,figsize=[12,4])\n",
    "subset_sst.analysed_sst.plot(ax=axes[0])\n",
    "subset_sst.mask.plot(ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask out land values using .where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sst_masked = subset_sst.where(subset_sst.mask==1)\n",
    "subset_sst_masked.analysed_sst.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in CCMP wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you search for ccmp you get all the different products, easier to look up on podaac website \n",
    "# the dataset id for the product you want\n",
    "dataset_id = 'PODAAC-CCF30-01XXX'\n",
    "gresult = p.granule_search(dataset_id=dataset_id,\n",
    "                           start_time=start_time,\n",
    "                           end_time=end_time,\n",
    "                           items_per_page='100')\n",
    "urls = putil.PodaacUtils.mine_opendap_urls_from_granule_search(gresult)\n",
    "urls_wnd = [w[:-5] for w in urls]  #remove html from urlsurls_sst = [w.replace('-tools.jpl.nasa.gov/drive/files/', '-opendap.jpl.nasa.gov/opendap/') for w in urls_sst]\n",
    "print('num files:',len(urls_wnd))\n",
    "print(urls_wnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the mean using coordinates\n",
    "* CCMP is a 6-hourly dataset, using .mean to find the daily average and make it easier to compare to daily SSTs\n",
    "* Here was want to do a daily average, so we will use .mean('time')\n",
    "* To do a spatial average you would use a dict-like container of coordinates to average over, for example .mean({'lat','lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wnd = xr.open_dataset(urls_wnd[0])\n",
    "ds_wnd = ds_wnd.mean('time')\n",
    "print(ds_wnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some gridded datasets go from -180 to -180 longitude, others from 0-360.  If you want to compare data, or use many cartopy routines, you will need to know how to switch from one to the other easily.\n",
    "\n",
    "*  let's change the longitude coordinates using [.coords](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.coords.html) and then [.sortby](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.sortby.html) |\n",
    "\n",
    "* this bit of code can be really useful if you open lots of gridded datasets.  I keep it on a post-it note on my desktop.\n",
    "\n",
    "## To get from 0-360 to -180-180\n",
    "```\n",
    "ds.coords['lon'] = np.mod(ds.coords['lon'] + 180,360) - 180  \n",
    "ds = ds.sortby(ds.lon)\n",
    "```\n",
    "\n",
    "## To get from -180-180 to 0-360\n",
    "```\n",
    "ds.coords['lon'] = np.mod(ds['lon'], 360)\n",
    "ds = ds_ccmp.sortby(ds.lon)\n",
    "```\n",
    "\n",
    "Change the CCMP datat from 0-360 to -180-180 below and then print out the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wnd.coords['lon'] = np.mod(ds_wnd.coords['lon'] + 180,360) - 180\n",
    "ds_wnd = ds_wnd.sortby(ds_wnd.lon)\n",
    "print(ds_wnd.lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate wind speed and direction from the vectors\n",
    "* use numpy operators to calculate the square root and arctan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wnd['wind_speed'] = np.sqrt(ds_wnd.uwnd**2 + ds_wnd.vwnd**2)\n",
    "ds_wnd['wind_dir'] = np.arctan2(ds_wnd.vwnd,ds_wnd.uwnd)/np.pi*180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that the lon -180 to 180, subset the data same as you did for the SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_wnd = ds_wnd.sel(lat=slice(15,45),lon=slice(-100,-40))\n",
    "print(subset_wnd)\n",
    "#subset_wnd.analysed_sst.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation and masking data\n",
    "\n",
    "* To compare the data, apply similar land masks.  \n",
    "* Since the winds don't include a land mask, use the SST land mask on the wind data, but they aren't on the same grid.  \n",
    "* Use .interp to put them on the same grid then mask the dataset together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the lat and lon for each dataset\n",
    "print(subset_sst.lon[0:5].data)\n",
    "print(subset_wnd.lon[0:5].data)\n",
    "print(subset_sst.lat[0:5].data)\n",
    "print(subset_wnd.lat[0:5].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation and masking\n",
    "\n",
    "* subset the data, interpolate it onto the ostia grid, then mask it.\n",
    "* mask ostia \n",
    "* show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use interp_like to automatically interpolate the data in time and space, but here only space\n",
    "#subset_mur_interp = subset_mur.isel(time=0).interp_like(subset_ostia)\n",
    "\n",
    "# use interp to interpolate the mur data in space onto the ostia grid\n",
    "subset_sst_interp = subset_sst.interp(lat=subset_wnd.lat,lon=subset_wnd.lon,method='nearest')\n",
    "# now use the ostia mask on the interpolated mur sst data\n",
    "subset_wnd_masked = subset_wnd.where(subset_sst_interp.mask==1)\n",
    "\n",
    "#make a figure showing new datasets\n",
    "fig, axes = plt.subplots(ncols=2,figsize=[16,4])\n",
    "subset_wnd_masked.wind_speed.plot(ax=axes[0])\n",
    "(subset_sst_interp.analysed_sst-273.15).plot(ax=axes[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram and subplots\n",
    "\n",
    "* Create a figure with two axes using `fig, axes = plt.supplots(ncols=2)`\n",
    "\n",
    "* To plot on a specific ax you need to set `ax = axes[0]` or `ax = axes[1]` in the hist argument\n",
    "\n",
    "* Plot the ocean winds histogram on the first axes using [.plot.hist()](http://xarray.pydata.org/en/stable/generated/xarray.plot.hist.html) and the global land/ocean winds on the next\n",
    "\n",
    "* Change the number of bins using an argument in hist eg.  `bins=20`\n",
    "\n",
    "* Different [arguments](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html#matplotlib.pyplot.hist) for .hist  trying making a PDF by using density = True  or change the style of the plot using `histtype = 'step'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2,figsize=[12,4])\n",
    "subset_wnd_masked.wind_speed.plot.hist(bins=20,ax=axes[0],density = True,histtype='step')\n",
    "subset_sst.analysed_sst.plot.hist(bins=20,ax=axes[1],density = True,histtype='step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare time series of the cold wake after Hurricane as measured by MUR and OSTIA SSTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When you open a multi-file dataset, xarray uses dask for lasy loading.  \n",
    "* Lazy loading: It mostly just loads the metadata. You can do data searching, selecting, subsetting without acutally loading the data. \n",
    "* Here we have loaded in 30 days of data for two very high resolution SST global datasets.  Before we actually load the data, we are going to want to do some subsetting so that it will fit into our memory.\n",
    "* Notice below when you print out the dataset details that they are all stored as dask.array types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sst = xr.open_mfdataset(urls_sst,coords='minimal')\n",
    "ds_wnd = xr.open_mfdataset(urls_wnd,coords='minimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shift wnd coordinates, subset, take time mean\n",
    "ds_wnd.coords['lon'] = np.mod(ds_wnd.coords['lon'] + 180,360) - 180\n",
    "ds_wnd = ds_wnd.sortby(ds_wnd.lon)\n",
    "\n",
    "#cal wind speed/dir\n",
    "ds_wnd['wind_speed'] = np.sqrt(ds_wnd.uwnd**2 + ds_wnd.vwnd**2)\n",
    "ds_wnd['wind_dir'] = np.arctan2(ds_wnd.vwnd,ds_wnd.uwnd)/np.pi*180\n",
    "\n",
    "#subset data\n",
    "subset_sst = ds_sst.sel(lat=slice(15,45),lon=slice(-100,-40))\n",
    "subset_wnd = ds_wnd.sel(lat=slice(15,45),lon=slice(-100,-40))\n",
    "\n",
    "subset_sst_interp = subset_sst.interp(lat=subset_wnd.lat,lon=subset_wnd.lon,method='nearest')\n",
    "# now use the sst mask on the wnd data\n",
    "subset_wnd_masked = subset_wnd.where(subset_sst_interp.mask==1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2,figsize=[12,4])\n",
    "(subset_sst.analysed_sst[-1,:,:]-subset_sst.analysed_sst[0,:,:]).plot(vmin=-1,vmax=1,ax=axes[0])\n",
    "subset_wnd_masked.wind_speed.max('time').plot(ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where can I find more info?\n",
    "\n",
    "### For more information about xarray\n",
    "\n",
    "- Read the [online documentation](http://xarray.pydata.org/)\n",
    "- Ask questions on [StackOverflow](http://stackoverflow.com/questions/tagged/python-xarray)\n",
    "- View the source code and file bug reports on [GitHub](http://github.com/pydata/xarray/)\n",
    "\n",
    "### For more doing data analysis with Python:\n",
    "\n",
    "- Thomas Wiecki, [A modern guide to getting started with Data Science and Python](http://twiecki.github.io/blog/2014/11/18/python-for-data-science/)\n",
    "- Wes McKinney, [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do) (book)\n",
    "\n",
    "### Packages building on xarray for the geophysical sciences\n",
    "\n",
    "For analyzing GCM output:\n",
    "\n",
    "- [xgcm](https://github.com/xgcm/xgcm) by Ryan Abernathey\n",
    "- [oogcm](https://github.com/lesommer/oocgcm) by Julien Le Sommer\n",
    "- [MPAS xarray](https://github.com/pwolfram/mpas_xarray) by Phil Wolfram\n",
    "- [marc_analysis](https://github.com/darothen/marc_analysis) by Daniel Rothenberg\n",
    "\n",
    "Other tools:\n",
    "\n",
    "- [windspharm](https://github.com/ajdawson/windspharm): wind spherical harmonics by Andrew Dawson\n",
    "- [eofs](https://github.com/ajdawson/eofs): empirical orthogonal functions by Andrew Dawson\n",
    "- [infinite-diff](https://github.com/spencerahill/infinite-diff) by Spencer Hill \n",
    "- [aospy](https://github.com/spencerahill/aospy) by Spencer Hill and Spencer Clark\n",
    "- [regionmask](https://github.com/mathause/regionmask) by Mathias Hauser\n",
    "- [salem](https://github.com/fmaussion/salem) by Fabien Maussion\n",
    "\n",
    "Resources for teaching and learning xarray in geosciences:\n",
    "- [Fabien's teaching repo](https://github.com/fmaussion/teaching): courses that combine teaching climatology and xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dresult = p.dataset_search(keyword='ostia',start_time='2018-09-01T00:00:00Z',end_time='2018-09-15T23:59:59Z')\n",
    "#ccmp\n",
    "gresult = p.granule_search(dataset_id='PODAAC-GHMWI-4FR05',start_time='2018-09-01T00:00:00Z',end_time='2018-09-30T23:59:59Z')\n",
    "#ostia\n",
    "#gresult = p.granule_search(dataset_id='PODAAC-GHOST-4FK02',start_time='2018-09-01T00:00:00Z',end_time='2018-09-30T23:59:59Z')\n",
    "#use podaac drive to find we provide a convenience function which enables easy access to all Drive urls\n",
    "urls = d.mine_drive_urls_from_granule_search(granule_search_response=gresult)\n",
    "urls_ostia = [w.replace('-tools.jpl.nasa.gov/drive/files/', '-opendap.jpl.nasa.gov/opendap/') for w in urls]\n",
    "print(urls_ostia)\n",
    "url = urls_ostia[0] #'https://podaac-opendap.jpl.nasa.gov/opendap/allData/ghrsst/data/GDS2/L4/GLOB/UKMO/OSTIA/v2/2018/255/20180912120000-UKMO-L4_GHRSST-SSTfnd-OSTIA-GLOB-v02.0-fv02.0.nc'\n",
    "ds_sst_ostia = xr.open_dataset(url)\n",
    "subset_ostia = ds_sst_ostia.sel(lat=slice(15,45),lon=slice(-100,-40))\n",
    "print(subset_ostia)\n",
    "subset_ostia.analysed_sst.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.get_backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
