{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cruise collocation with gridded data \n",
    "  \n",
    "Authors\n",
    "* [Dr Chelle Gentemann](mailto:gentemann@esr.org)    - Earth and Space Research, USA\n",
    "* [Dr Marisol Garcia-Reyes](mailto:marisolgr@faralloninstitute.org)  - Farallon Institute, USA \n",
    "-------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of this tutorial\n",
    "\n",
    "1. Opening data\n",
    "1. Collocating satellite data with a cruise dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "## Import python packages\n",
    "\n",
    "You are going to want numpy, pandas, matplotlib.pyplot and xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore') # filter some warning messages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A nice cartopy tutorial is [here](http://earthpy.org/tag/visualization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocating Saildrone cruise data with satellite SSTs \n",
    "\n",
    "* read in the Saildrone data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NCEI trajectory format uses 'obs' as the coordinate.  This is an example of an 'older' style of data formatting that doesn't really mesh well with modern software capabilities. \n",
    "\n",
    "* So, let's change that by using [.swap_dims](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.swap_dims.html) to change the coordinate from `obs` to `time`\n",
    "* Another thing, `latitude` and `longitude` are just long and annoying, lets [.rename](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.rename.html) them to `lat` and `lon`\n",
    "\n",
    "* Finally, the first and last part of the cruise the USV is being towed, so let's only include data from `2018-04-12T02` to `2018-06-10T18`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use first url if not online\n",
    "#url = '../data/saildrone-gen_4-baja_2018-sd1002-20180411T180000-20180611T055959-1_minutes-v1.nc'\n",
    "url = 'https://podaac-opendap.jpl.nasa.gov/opendap/hyrax/allData/insitu/L2/saildrone/Baja/saildrone-gen_4-baja_2018-sd1002-20180411T180000-20180611T055959-1_minutes-v1.nc'\n",
    "\n",
    "ds_usv = xr.open_dataset(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv2 = ds_usv.isel(trajectory=0)\\\n",
    "                .swap_dims({'obs':'time'})\\\n",
    "                .rename({'longitude':'lon','latitude':'lat'})\n",
    "\n",
    "ds_usv_subset = ds_usv2.sel(time=slice('2018-04-12T02','2018-06-10T18')) \n",
    "\n",
    "start_time = pd.to_datetime(str(ds_usv_subset.time.min().data)).strftime('%Y-%m-%dT%H:%m:%SZ') \n",
    "end_time = pd.to_datetime(str(ds_usv_subset.time.max().data)).strftime('%Y-%m-%dT%H:%m:%SZ') \n",
    "\n",
    "print('start: ',start_time,'end: ',end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's open 2 months of 0.2 km AVHRR OI SST data\n",
    "`xarray`can open multiple files at once using string pattern matching. `xr.open_mfdataset()` \n",
    "  \n",
    "## Now open multiple files (lazy) using [.open_mfdataset](http://xarray.pydata.org/en/stable/generated/xarray.open_mfdataset.html#xarray.open_mfdataset)\n",
    "\n",
    "* use the option `coords = 'minimal'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = '../../data/avhrr_oi/*.nc'\n",
    "\n",
    "ds_sst = xr.open_mfdataset(files,coords = 'minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see what one day looks like\n",
    "\n",
    "* add coastlines `ax.coastlines()`\n",
    "* add gridlines `ax.gridlines()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = ds_sst.sst[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.Orthographic(-80, 35))\n",
    "\n",
    "sst.plot(ax=ax, transform=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the figure\n",
    "* colormap `cmap='jet'\n",
    "* colorscale `vmin=-1,vmax=34`\n",
    "* add land `ax.stock_imag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.Orthographic(-80, 35))\n",
    "\n",
    "sst.plot(ax=ax, transform=ccrs.PlateCarree(),cmap='jet',vmin=-1,vmax=34)\n",
    "ax.stock_img()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the sst data and notice the longitude range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Again with the 0-360 vs -180-180.  Change it up below!\n",
    "* `ds_sst.coords['lon'] = np.mod(ds_sst.coords['lon'] + 180,360) - 180`\n",
    "* remember to sort by lon, `.sortby(ds_sst.lon)`\n",
    "* Also, look at the coordinates, there is an extra one `zlev`.  Drop it using .isel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sst.coords['lon'] = np.mod(ds_sst.coords['lon'] + 180,360) - 180     #change lon -180to180\n",
    "\n",
    "\n",
    "ds_sst = ds_sst.sortby(ds_sst.lon) # sort lon\n",
    "\n",
    "ds_sst = ds_sst.isel(zlev=0)    #isel zlev\n",
    "\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`open_mfdataset` even puts them in the right order for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sst.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is all this data uncompressed? Will it fit into memory?\n",
    "Use `.nbytes` / 1e9  to convert it into gigabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('file size (GB):', ds_sst.nbytes / 1e9)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xarray interpolation won't run on chunked dimensions.  \n",
    "1. First let's subset the data to make it smaller to deal with by using the cruise lat/lons\n",
    "    * Find the max/min of the lat/lon using `.lon.min().data`\n",
    "\n",
    "1. Now load the data into memory (de-Dask-ify) it using `.load()`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 from above\n",
    "lon_min,lon_max = ds_usv_subset.lon.min().data,ds_usv_subset.lon.max().data\n",
    "\n",
    "lat_min,lat_max = ds_usv_subset.lat.min().data,ds_usv_subset.lat.max().data\n",
    "\n",
    "subset = ds_sst.sel(lon=slice(lon_min,lon_max),\n",
    "                    lat=slice(lat_min,lat_max))\n",
    "\n",
    "print('file size (GB):', subset.nbytes / 1e9)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 from above\n",
    "\n",
    "subset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate USV data with MUR data\n",
    "There are different options when you interpolate.  First, let's just do a linear interpolation using [.interp()](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.interp.html#xarray.Dataset.interp)\n",
    "\n",
    "`Dataset.interp(coords=None, method='linear', assume_sorted=False, kwargs={}, **coords_kwargs))`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_collocated = subset.interp(lat=ds_usv_subset.lat,lon=ds_usv_subset.lon,time=ds_usv_subset.time,method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate USV data with MUR data\n",
    "There are different options when you interpolate.  First, let's just do a nearest point rather than interpolate the data\n",
    "`method = 'nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_collocated_nearest = subset.interp(lat=ds_usv_subset.lat,lon=ds_usv_subset.lon,time=ds_usv_subset.time,method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, calculate the different in SSTs and print the [.mean()](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.mean.html#xarray.DataArray.mean) and [.std()](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.std.html#xarray.DataArray.std)\n",
    "For the satellite data we need to use `sst` and for the USV data we need to use `TEMP_CTD_MEAN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = ds_collocated_nearest.sst-ds_usv_subset.TEMP_CTD_MEAN\n",
    "print('mean difference = ',dif.mean().data)\n",
    "print('STD = ',dif.std().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xarray can do more!\n",
    "\n",
    "* concatentaion\n",
    "* open network located files with openDAP\n",
    "* import and export Pandas DataFrames\n",
    "* .nc dump to \n",
    "* groupby_bins\n",
    "* resampling and reduction\n",
    "\n",
    "For more details, read this blog post: http://continuum.io/blog/xray-dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_collocated_nearest.to_netcdf('./data/new file.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where can I find more info?\n",
    "\n",
    "### For more information about xarray\n",
    "\n",
    "- Read the [online documentation](http://xarray.pydata.org/)\n",
    "- Ask questions on [StackOverflow](http://stackoverflow.com/questions/tagged/python-xarray)\n",
    "- View the source code and file bug reports on [GitHub](http://github.com/pydata/xarray/)\n",
    "\n",
    "### For more doing data analysis with Python:\n",
    "\n",
    "- Thomas Wiecki, [A modern guide to getting started with Data Science and Python](http://twiecki.github.io/blog/2014/11/18/python-for-data-science/)\n",
    "- Wes McKinney, [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do) (book)\n",
    "\n",
    "### Packages building on xarray for the geophysical sciences\n",
    "\n",
    "For analyzing GCM output:\n",
    "\n",
    "- [xgcm](https://github.com/xgcm/xgcm) by Ryan Abernathey\n",
    "- [oogcm](https://github.com/lesommer/oocgcm) by Julien Le Sommer\n",
    "- [MPAS xarray](https://github.com/pwolfram/mpas_xarray) by Phil Wolfram\n",
    "- [marc_analysis](https://github.com/darothen/marc_analysis) by Daniel Rothenberg\n",
    "\n",
    "Other tools:\n",
    "\n",
    "- [windspharm](https://github.com/ajdawson/windspharm): wind spherical harmonics by Andrew Dawson\n",
    "- [eofs](https://github.com/ajdawson/eofs): empirical orthogonal functions by Andrew Dawson\n",
    "- [infinite-diff](https://github.com/spencerahill/infinite-diff) by Spencer Hill \n",
    "- [aospy](https://github.com/spencerahill/aospy) by Spencer Hill and Spencer Clark\n",
    "- [regionmask](https://github.com/mathause/regionmask) by Mathias Hauser\n",
    "- [salem](https://github.com/fmaussion/salem) by Fabien Maussion\n",
    "\n",
    "Resources for teaching and learning xarray in geosciences:\n",
    "- [Fabien's teaching repo](https://github.com/fmaussion/teaching): courses that combine teaching climatology and xarray\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
